[
  {
    "objectID": "ResBazPlanning.html#r",
    "href": "ResBazPlanning.html#r",
    "title": "ResBaz 2023 - Scheduling Assistance",
    "section": "R",
    "text": "R\n\nLet‚Äôs start with R.\nIt is very commonly used\nand it originated from research needs to undertake statistical analysis and to create graphics.\nNowadays, there are heaps of things that you can do with R and these are presented in the session\n‚ÄúIntroduction to R and R Studio‚Äù\n\nWhat you learned there will be expanded on in ‚ÄúUsing R for statistical analysis‚Äù and even more in ‚ÄúHands-on statistical analysis with R‚Äù"
  },
  {
    "objectID": "ResBazPlanning.html#python",
    "href": "ResBazPlanning.html#python",
    "title": "ResBaz 2023 - Scheduling Assistance",
    "section": "Python",
    "text": "Python\n\nAnother popular programming language in the research Community is Python.\nPython is commonly employed for all kinds of research-tasks.\nTo get an overview, we reommend attending the taster session: ‚ÄúHow Can Python Help Your Research?‚Äù.\n\nIf you have or already had developed a taste for Python, ‚ÄúIntroduction to the Python Programming Language‚Äù gets you started with hands-on coding in Python\n\nIf you face challenges with handling/changing/manipulating not one but hundreds or more of files, ‚ÄúPython for Image Manipulation and Repeatable Research Pipelines‚Äù helps you in making Python do the work so you can free up some time to focus on research"
  },
  {
    "objectID": "ResBazPlanning.html#cli",
    "href": "ResBazPlanning.html#cli",
    "title": "ResBaz 2023 - Scheduling Assistance",
    "section": "CLI",
    "text": "CLI\n\nEven though you can run many aspects of R and Python in a graphical user interface or gui, so independent of a command-line interface or CLI, many other software packages do have a cli version\nSome also refer to these as the terminal version.\n\nSometimes this might have even more functionality or\nyou can automate tedious tasks\nor its use contributes to a repeatable and hence reproduicble resareach workflow.\nThese things become more and more important."
  },
  {
    "objectID": "ResBazPlanning.html#cli2",
    "href": "ResBazPlanning.html#cli2",
    "title": "ResBaz 2023 - Scheduling Assistance",
    "section": "CLI2",
    "text": "CLI2\n\nIn the session ‚Äúintroduction to command line‚Äù you will be familiarized with important commands but also the related mindset\nand syntax.\n\nA fancy way os daying how you have to type things out.\nOften upper or lower case, dashes and the sequence matter.\n\nAs a next step, you can apply these skills in the session ‚Äúusing the command line to find replace and manipulate data‚Äù\n\nThat session title gives a lot away\nand might save you hours of work"
  },
  {
    "objectID": "UpskillingResearchersInML.html#uoa-workshops",
    "href": "UpskillingResearchersInML.html#uoa-workshops",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "UoA workshops",
    "text": "UoA workshops\n\n\n\nAudience: The University of Auckland (UoA) researchers\nTwo runs\n\nRun #1: March 2023\nRun #2: September 2023\n\nWell-received\n\nfiltering by mandatory Expression of Interest (EoI)\nabout 100 applications for 40 spots"
  },
  {
    "objectID": "UpskillingResearchersInML.html#nesi-workshops",
    "href": "UpskillingResearchersInML.html#nesi-workshops",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "NeSI workshops",
    "text": "NeSI workshops\n\n\n First ML101 workshop at eResearch NZ 2021\n\n\nAudience: Aotearoa ‚Äì NZ researchers\nML 101\n\nIntro to Machine Learning\nstarted in 2021\n7 workshops (in person, online)\n127 attendees in total (from 10 to 32)\n\nML 102\n\nIntro to Deep Learning (CNNs)\nstarted in 2022\n2 workshops (online)\n44 attendees in total (20 and 24)\n\nMixture of direct registration and EoIs"
  },
  {
    "objectID": "UpskillingResearchersInML.html#recommendations",
    "href": "UpskillingResearchersInML.html#recommendations",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "Recommendations",
    "text": "Recommendations\nThere will be a lot of interest so‚Ä¶\n\nuse an Expression of Interest for registration and filter,\n30 participants is a good number for an online training,\nexpect people to not show up (if free and online)."
  },
  {
    "objectID": "UpskillingResearchersInML.html#uoa-workshops-1",
    "href": "UpskillingResearchersInML.html#uoa-workshops-1",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "UoA workshops",
    "text": "UoA workshops\n\n\n\nonline only event: Zoom.us\nBYOD (bring your own device)\nmajor deviation from The Carpentries: No local Python installs\nGoolge Colab ,a browser-based Jupyter Notebook using Google infrastructure (a virtual machine; a GPU can be added)\n\n\n\n\n\nGoogle Colab in a Browser"
  },
  {
    "objectID": "UpskillingResearchersInML.html#nesi-workshops-1",
    "href": "UpskillingResearchersInML.html#nesi-workshops-1",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "NeSI workshops",
    "text": "NeSI workshops\n\n\n\n JupyterLab session running on Jupyter-on-NeSI\n\n\nOnline and in person\n\n2 delivered in person (1 had wifi issues üòì)\n5 delivered online\n\nUse Jupyter-on-NeSI\n\nJupyterHub platform\nRequires a NeSI account\nML101: 2 cores & 4 GB of RAM\nML102: 4 cores & 8 GB of RAM\n\nUse Slurm-based job for GPU training (a little bit)\nTip: make sure the Platform team does not schedule upgrades that day üò¨‚Ä¶"
  },
  {
    "objectID": "UpskillingResearchersInML.html#recommendations-1",
    "href": "UpskillingResearchersInML.html#recommendations-1",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "Recommendations",
    "text": "Recommendations\n\nMake it online\nLeverage online computational platforms (Google Colab, JupyterHub, Open OnDemand‚Ä¶)\nNo need for GPU to start (or small ones on Google Colab available)"
  },
  {
    "objectID": "UpskillingResearchersInML.html#uoa-workshops-2",
    "href": "UpskillingResearchersInML.html#uoa-workshops-2",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "UoA workshops",
    "text": "UoA workshops\n\n\nRun #1\n\n\n\nTime Budget\nActivity\n\n\n\n\ntwo afternoons (8h)\nPython\n\n\none afternoon (4h)\nML\n\n\ntwo afternoons (8h)\nDL\n\n\n\nRun #2 \n\n\n\nTime Budget\nActivity\n\n\n\n\ntwo afternoons (8h)\nML\n\n\ntwo afternoons (8h)\nDL\n\n\n\n\n\nall workshops took place in the same week\nno mixing and matching, signing up = coming to all sessions\nMajor adjustment for Run #2: Python as a prerequisite, not part of the series"
  },
  {
    "objectID": "UpskillingResearchersInML.html#nesi-workshops-2",
    "href": "UpskillingResearchersInML.html#nesi-workshops-2",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "NeSI workshops",
    "text": "NeSI workshops\n\n\n\nML 101\n\n6 hours with 3 breaks ‚òï\nat first in one day\nnow split over 2 mornings\n\nML 102\n\n3 hours with 2 breaks üçµ\n\nIndependent workshops\nBut organised ‚Äúclose‚Äù to each other\n\n\n ML101 runsheet, used to keep track of time"
  },
  {
    "objectID": "UpskillingResearchersInML.html#recommendations-2",
    "href": "UpskillingResearchersInML.html#recommendations-2",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "Recommendations",
    "text": "Recommendations\n\nSplit/shorter sessions (bearing in mind the scheduling challenges for researchers)\nStick to scheduled breaks\nFollow best practices for online audiences:\n\nget a Zoom DJ, some helpers, get multiple co-hosts\nkeep a QA document\nprepare your intro and outro\nmake attendees join from the same computer running the code\nWebinar: Tips & tricks for hosting a successful online event"
  },
  {
    "objectID": "UpskillingResearchersInML.html#uoa-workshops-3",
    "href": "UpskillingResearchersInML.html#uoa-workshops-3",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "UoA workshops",
    "text": "UoA workshops\n\n\n\nLesson Title\nStatus\nRun #1\nRun #2\n\n\n\n\n\nProgramming with Python\nReleased\nMon, Tue\n-\n\n\n\nIntroduction to Machine Learning with Scikit Learn\nAlpha\nWed\nMon, Tue\n\n\n\nIntroduction to Deep Learning\nBeta\nThu, Fri\nWed, Thu"
  },
  {
    "objectID": "UpskillingResearchersInML.html#nesi-workshops-3",
    "href": "UpskillingResearchersInML.html#nesi-workshops-3",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "NeSI workshops",
    "text": "NeSI workshops\n\n\n My rehearsal and source of inspiration üíì\n\nNeSI workshops\n\nML 101 ‚Äì github.com/nesi/sklearn_tutorial\n\nScikit-learn Tutorial by Jake Vanderplas\nonline recordings exist  (very good to rehearse!)\nJupyter Notebook based\nvery few changes (updated package version)\n\nML 102 ‚Äì github.com/nesi/ml102_workshop\n\nTensorFlow tutorials\nJupyter Notebook based\nadded an introduction\nadded section to submit a Slurm job"
  },
  {
    "objectID": "UpskillingResearchersInML.html#recommendations-3",
    "href": "UpskillingResearchersInML.html#recommendations-3",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "Recommendations",
    "text": "Recommendations\nCeR and NeSI independently decided to base the workshops on existing material.\n\nDon‚Äôt reinvent the wheel\nReuse/adapt content"
  },
  {
    "objectID": "UpskillingResearchersInML.html#section",
    "href": "UpskillingResearchersInML.html#section",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "",
    "text": "Machine Learning\n\nData preparation\nSupervised vs.¬†unsupervised learning\n\nregression\nclassification\nclustering\ndimensionality reduction\n\nEnsemble models (random forests)\nValidation\n\ntrain/test/validation split\ncross-validation\nvalidation and learning curves\n\n\n\nDeep Learning\n\nModel architectures\n\nMulti-layer perceptron\nConvolutional neural network  (CNN | computer vision)\n\nModel training\n\noptimisers and mini-batch\noverfitting and early stopping\ndata augmentation\ndropout, batch normalisation, ‚Ä¶\n\nTransfer learning"
  },
  {
    "objectID": "UpskillingResearchersInML.html#recommendations-4",
    "href": "UpskillingResearchersInML.html#recommendations-4",
    "title": "Upskilling Researchers in Machine Learning",
    "section": "Recommendations",
    "text": "Recommendations\n\nRandom forest is a good first non-linear model to learn\n\nintuitive to understand how it works\ngood performances on tabular data\ndoesn‚Äôt require too much care in terms of data preparation\n\nResist the temptation of MLP (multi-layer perceptron) for an ML intro\n\nrequire more notions (architecture, training, data preprocessing, ‚Ä¶)\nkeep it for Deep Learning introduction"
  },
  {
    "objectID": "JoiningTheDots.html#more-details-about-data-sensitivity-etc.",
    "href": "JoiningTheDots.html#more-details-about-data-sensitivity-etc.",
    "title": "Joining the dots for modern data science workflows",
    "section": "More details about data sensitivity, etc.",
    "text": "More details about data sensitivity, etc.\n\n\n\n\n\n\nRecommended ResBaz sessions\n\n\n\nJust before this one: Managing Research Data (which just ran prior to this session;\n\nrepeated workshop at University of Auckland)\n\nPotentially still available after this session:\n\nAn introduction to cloud security for researchers\nData Management Planning\nHealth care data for research at the University of Auckland\nUsing digital tools for transcription\nResearch Data Collection & Surveys with REDCap: An Overview\nTikanga, MƒÅori Research Ethics and MƒÅori Data Sovereignty\nIntroduction to Qualtrics for Research Surveys"
  },
  {
    "objectID": "JoiningTheDots.html#component-1-the-physical-computer",
    "href": "JoiningTheDots.html#component-1-the-physical-computer",
    "title": "Joining the dots for modern data science workflows",
    "section": "Component 1: the physical computer",
    "text": "Component 1: the physical computer\n\n\nthis can be many things\n\nyour local laptop (don‚Äôt forget it on the bus üöå)\nyour office computer üè¢\nyour lab-groups‚Äô computer üî¨\na Virtual Machine üì°\n\n3 sentences about VMs\nwe will use one in our project\n\na cloud resource ‚òÅÔ∏è (might be obfuscated, might be a server similar to a VM)"
  },
  {
    "objectID": "JoiningTheDots.html#component-2-the-operating-system",
    "href": "JoiningTheDots.html#component-2-the-operating-system",
    "title": "Joining the dots for modern data science workflows",
    "section": "Component 2: the operating system",
    "text": "Component 2: the operating system\n\n\nSelected tools are maximised for\n\nbeing Operating System (OS) agnostic\nthey should work on many systems\nsome (!) trouble-shotting in aforementioned Drop-in Clinic or over Slack\n\n\n\n\n\n\n\n\nNote\n\n\nbecause of the way we interact with the core-coding task, we won‚Äôt see too much of the OS"
  },
  {
    "objectID": "JoiningTheDots.html#component-3-the-programming-language",
    "href": "JoiningTheDots.html#component-3-the-programming-language",
    "title": "Joining the dots for modern data science workflows",
    "section": "Component 3: the programming language",
    "text": "Component 3: the programming language\n\n\nwe will use Python üêç\nPython vs.¬†R vs.¬†C vs.¬†Rust vs.¬†JS, ‚Ä¶ is out of scope\nTry one of these sessions If your goal is‚Ä¶\n\n‚Ä¶ efficient Machine Learning: Julia\n‚Ä¶ statistics and refined plots (yes, I am looking at you, ggplot2): R\n‚Ä¶ the Swiss Army Knife¬Æ: Python\n\n\n(all these ResBaz session are running concurrently on Wed. 1-5pm)"
  },
  {
    "objectID": "JoiningTheDots.html#component-4-libraries",
    "href": "JoiningTheDots.html#component-4-libraries",
    "title": "Joining the dots for modern data science workflows",
    "section": "Component 4: Libraries",
    "text": "Component 4: Libraries\n\n\nWe will talk more about packages/libraries in due course\nFor now: Python has a vast amount of libraries\nwe will use GeoPandas among others\nefficiently handling these might appear daunting\n\nbut we will show you some tricks\nmany others have done this before!"
  },
  {
    "objectID": "JoiningTheDots.html#component-5-the-programming-environment",
    "href": "JoiningTheDots.html#component-5-the-programming-environment",
    "title": "Joining the dots for modern data science workflows",
    "section": "Component 5: the programming environment",
    "text": "Component 5: the programming environment\n We have two main appraoches\n\n\n\ncommand-line interface (aka CLI/terminal/console/shell/BaSH/ZSH/Fish/‚Ä¶):\n\nautomatically, for ex. every night at 11pm (cron-job)\nchain one scripts output as an input to another script (build a pipeline)\n\n\n\nJupyter Notbooks, etc.:\n\ndevelop your code\nexplore your data\nget interactivity\nrun bits and pieces in Isolation"
  },
  {
    "objectID": "JoiningTheDots.html#option-a-command-line-based",
    "href": "JoiningTheDots.html#option-a-command-line-based",
    "title": "Joining the dots for modern data science workflows",
    "section": "Option A: Command-line-based",
    "text": "Option A: Command-line-based\n\nwe can get a lot done by only using a CLI\nopen a terminal locally or log in to a VM (via SSH, etc.)\nwe can code in a text editor\n\nthat can be VI/VIM/nano/‚Ä¶\n\n\n\n\n\n\n\n\nRecommended ResBaz session\n\n\nIntroduction to the Command Line (Wed. 10am-3pm)"
  },
  {
    "objectID": "JoiningTheDots.html#option-a-in-action",
    "href": "JoiningTheDots.html#option-a-in-action",
    "title": "Joining the dots for modern data science workflows",
    "section": "Option A in action",
    "text": "Option A in action"
  },
  {
    "objectID": "JoiningTheDots.html#option-b-gui-based-.py-files",
    "href": "JoiningTheDots.html#option-b-gui-based-.py-files",
    "title": "Joining the dots for modern data science workflows",
    "section": "Option B: GUI-based; .py files",
    "text": "Option B: GUI-based; .py files\nGUI = graphical user interface\n\nwhy do we use a GUI? To get help!\n\nsyntax highlighting\nauto-complete\npotentially AI-support 1\n\nwe can use our local computer (, , ) or  x11/ rdp into a virtual machine\nthere is again quite a variety\nI pick Visusal Studio Code (VSC), others use Jetbrains PyCharm, etc.\n\nVSCodium: open-source adaption without telemetry; no MS VS Marketplace but its own; at times less smooth\n\n\n\n\npersonal experience: VSC is powerful, yet quite streamlined.\ndouble-edged-sword: simple vs.¬†overwhelming\nprevent you from having this feeling, too.\neach project (connection to a VM): own window,\n\ncan run mulitple concurrently\n\nsidebar (most things can be customised, put into other places, etc.) here it shows a file explorer.\n\nmaybe not impressive\nremote VM, not the local machine\neven drag and drop things. Really neat.\n\nwe have a (or several) built-in command-line applications (BaSH, ZSH, ‚Ä¶\n\nI can navigate to a sub-folder and click open terminal here)\n\ntop-right corner\n\nwhere the magic\nwe write our code\nseveral windows possible; we can have previews, ‚Ä¶\n\n\n\nAI: even if you try your best to do all correct, treat sensitive data respectfully, for example, use the University-provided systems,‚Ä¶ using tools like AI Coding Support (GitHub CoPilot) might make most of these efforts useless; sensitive data might (!) be fed back for training purposes, etc. If in doubt, take the pessimistic approach (expect that it calls home) and talk to relevant people (Ethics-advisors, eResearch support, supervisor,‚Ä¶)"
  },
  {
    "objectID": "JoiningTheDots.html#option-b---jupyter-notebooks.ipynb-files",
    "href": "JoiningTheDots.html#option-b---jupyter-notebooks.ipynb-files",
    "title": "Joining the dots for modern data science workflows",
    "section": "Option B - Jupyter Notebooks/.ipynb files:",
    "text": "Option B - Jupyter Notebooks/.ipynb files:\n\nmaximise the GUI-use: Jupyter Notebooks1\nImagine a pharmacy-student‚Äôs lab notebook.\n\nThere are some hard-facts (graphs, print-outs,‚Ä¶) and explanations around it\n\nin Jupyter, we can have code blocks, text blocks, images, ‚Ä¶\n\nto beautify we can use markdown syntax\n\na different take than MS-Word cusor-highlight-text-to-bold approach\n\n\nbut: Why add explanations/metadata in the first place? - collaboration/colleagues need to know rationale/units [\\(m\\) vs \\(mm\\)] - future-you:\n\nagain: FAIR and metadata, utlimately: get more research impact\n\n\n\nformerly IPythonNotebook, hence the file extension .ipynb"
  },
  {
    "objectID": "JoiningTheDots.html#option-b-in-action",
    "href": "JoiningTheDots.html#option-b-in-action",
    "title": "Joining the dots for modern data science workflows",
    "section": "Option B in action",
    "text": "Option B in action\n\n\n\nNow, VSC has syntax highlighting.\n\nreserved keyword, such as if changes colour\nit indents my new line\n\nindentation is very important in Python\n\nwhile you can do all that it is harded in a simplistic text editor\n\nsame idea; but instead of calling our script (the .py file) via the command-line, we can press the little play button\nturns our coded md to visually pleasing\none. See how our heading levels\ngive us a little ToC on the bottom-left?\nAnd we get the output below each cell.\nBonus: Once we have several cells, we can intentionally press the play button here and there; observe how the numbers change"
  },
  {
    "objectID": "JoiningTheDots.html#intermezzo-how-does-that-look-on-google-colab",
    "href": "JoiningTheDots.html#intermezzo-how-does-that-look-on-google-colab",
    "title": "Joining the dots for modern data science workflows",
    "section": "Intermezzo: How does that look on Google Colab",
    "text": "Intermezzo: How does that look on Google Colab"
  },
  {
    "objectID": "JoiningTheDots.html#vsc-and-github",
    "href": "JoiningTheDots.html#vsc-and-github",
    "title": "Joining the dots for modern data science workflows",
    "section": "VSC and GitHub",
    "text": "VSC and GitHub\n\n\n\nVSC we can either use the lefthand side-panel for git (once extension is installed), or we can use the CLI below to do\n\ngit status, git diff, git commit -am \"present-tense active what I did\"1, git push\n\nGitHub can also provide us with\n\nGitHub Actions (throw-away-VMs running on MSAzure)\nSome basic Project Management via Issues\nCollaboration (allow other to work on your code)\nprivate and public repos\nthere are academic discounts, ‚Ä¶\n\n\n\n \n\nexample: ‚ÄòFix typo in introduction to user guide‚Äô how to write proper commit messages here"
  },
  {
    "objectID": "JoiningTheDots.html#packages-a-gift-a-curse",
    "href": "JoiningTheDots.html#packages-a-gift-a-curse",
    "title": "Joining the dots for modern data science workflows",
    "section": "Packages üéÅ : A gift üëë & a curse ü§¨",
    "text": "Packages üéÅ : A gift üëë & a curse ü§¨\n\n\nA gift üëë because:\n\nPython makes it easy to integrate\nincredible amount of packages exist\nso no reinventing the wheel (build on other peoples‚Äô extended efforts)1\n\nA curse ü§¨ because:\n\nthings tend to break\n\npeople discontinue packages\n‚Äúbreaking changes‚Äù require us to change our syntax\npackages depend on other packages (think of a big treeüå≤)\n\n\n\nBut! We are not the first people to run into such challenges\n\npackage management: there are different ways of minimising that impact; let me show 3\n\nmanually creating a references.txt file (part of the following demo)\npip freeze &gt; references.txt (also part of the following demo)\npoetry\n\nthere are others, Anaconda, Hatch, just to name a few\n\n\nproper referencing is crucial, code is not different from other academic tasks in this respect"
  },
  {
    "objectID": "JoiningTheDots.html#mapping-our-geospatial-example-to-the-pyramid",
    "href": "JoiningTheDots.html#mapping-our-geospatial-example-to-the-pyramid",
    "title": "Joining the dots for modern data science workflows",
    "section": "Mapping our geospatial example to the Pyramid",
    "text": "Mapping our geospatial example to the Pyramid\n\n\n\nCategory\nDetails\n\n\n\n\nData Input\nDownload dataset 1 & 2\n\n\nComputer\nWe use a VM (on Nectar)\n\n\nOS\nWe use Ubuntu 22.4\n\n\nLanguage\nPython\n\n\nLibraries\ngeopandas among others\n\n\nIDE\nVSC to run a Jupyter Notebook (ssh to VM)\n\n\nCode\nOn GitHub\n\n\nResearch Outputs\nMap published to website/GitHub Action (bit out of scope)"
  },
  {
    "objectID": "JoiningTheDots.html#background",
    "href": "JoiningTheDots.html#background",
    "title": "Joining the dots for modern data science workflows",
    "section": "Background",
    "text": "Background\nRough workflow:\n\nWe download a dataset that contains the boundaries of New Zealand‚Äôs Statistical Areas (SA2) - details follow\nAnd another one that contains the population (i.e.¬†the number of people) of each SA2\nWe want to plot the boundaries and the population data on an interactive map in a browser\nWe put that on GitHub/a website\n\nDetails:\n\nStatsNZ decomposes New Zealand into Statistical Areas (SA)\n\neach SA should encapsule people of similar socio-economical status\nthere are 3 resolutions (SA1 = up to 500 people, SA2 = 1k-4k people, SA3 = 5k-50k people)\nwe pick SA2"
  },
  {
    "objectID": "LightningTalk.html#background",
    "href": "LightningTalk.html#background",
    "title": "Developing a Carpentries-style Machine Learning workshop",
    "section": "Background",
    "text": "Background\n\nMachine Learning (ML) or Artificial Intelligence (AI) are without a doubt hot topics\nEmpowering researchers to understand and use ML seems rewarding, but also challenging\nThe Carpentries  offer a proven teaching-style accounting for participants with limited IT experience\n\nCore aspects\n\nlive-coding\npositive attitude towards mistakes\nminimal prerequisites\nmaximising participant involvement\n\n\nThe CeR (Centre for eResearch) at the University of Auckland acquired funding to further develop and run a series of workshops (also referred to as ML-Carp)\nTwo iterations (referred to as Run #1 and Run#2) took place so far. In March and September 2023."
  },
  {
    "objectID": "LightningTalk.html#lesson-overview",
    "href": "LightningTalk.html#lesson-overview",
    "title": "Developing a Carpentries-style Machine Learning workshop",
    "section": "Lesson Overview",
    "text": "Lesson Overview\n\n\n\nLesson Title\nStatus\nRun #1\nRun #2\n\n\n\n\n\nProgramming with Python\nReleased\nMon, Tue\n-\n\n\n\nIntroduction to Machine Learning with Scikit Learn\nAlpha\nWed, Thu\nMon, Tue\n\n\n\nIntroduction to Deep Learning\nBeta\nFri\nWed, Thu\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n4h sessions over 4 consecutive afternoons\n\n\n\n\n\nDepending on Maturity, sessions were run with small changes or substantially (re)developed.\nOne major change was Goolge Colab  being used instead of local Python installs."
  },
  {
    "objectID": "LightningTalk.html#lesson-details",
    "href": "LightningTalk.html#lesson-details",
    "title": "Developing a Carpentries-style Machine Learning workshop",
    "section": "Lesson Details",
    "text": "Lesson Details\n\n\n\nProgramming with Python\nIntroduction to Machine Learning with Scikit Learn and Python\nIntroduction to deep learning\n\n\n\n\nPython Fundamentals\nIntroduction\nIntroduction\n\n\nAnalyzing Patient Data\nSupervised methods - Regression\nClassification by a neural network using Keras\n\n\nVisualizing Tabular Data\nSupervised methods - Classification\nMonitor the training process\n\n\nStoring Multiple Values in Lists\nEnsemble methods\nAdvanced layer types\n\n\nRepeating Actions with Loops\nUnsupervised methods - Clustering\nOutlook\n\n\nAnalyzing Data from Multiple Files\nUnsupervised methods - Dimensionality reduction\n\n\n\nMaking Choices\nNeural Networks\n\n\n\nCreating Functions\nEthics and the Implications of Machine Learning\n\n\n\nErrors and Exceptions\nFind out more\n\n\n\nDefensive Programming\n\n\n\n\nDebugging\n\n\n\n\nCommand-Line Programs"
  },
  {
    "objectID": "LightningTalk.html#participants-background",
    "href": "LightningTalk.html#participants-background",
    "title": "Developing a Carpentries-style Machine Learning workshop",
    "section": "Participants‚Äô Background",
    "text": "Participants‚Äô Background"
  },
  {
    "objectID": "LightningTalk.html#participants-os",
    "href": "LightningTalk.html#participants-os",
    "title": "Developing a Carpentries-style Machine Learning workshop",
    "section": "Participants‚Äô OS",
    "text": "Participants‚Äô OS"
  },
  {
    "objectID": "LightningTalk.html#participants-feelings---metrics",
    "href": "LightningTalk.html#participants-feelings---metrics",
    "title": "Developing a Carpentries-style Machine Learning workshop",
    "section": "Participants‚Äô Feelings - Metrics",
    "text": "Participants‚Äô Feelings - Metrics"
  },
  {
    "objectID": "LightningTalk.html#zoom-attendance",
    "href": "LightningTalk.html#zoom-attendance",
    "title": "Developing a Carpentries-style Machine Learning workshop",
    "section": "Zoom attendance",
    "text": "Zoom attendance"
  },
  {
    "objectID": "LightningTalk.html#participants-promotiondemotion",
    "href": "LightningTalk.html#participants-promotiondemotion",
    "title": "Developing a Carpentries-style Machine Learning workshop",
    "section": "Participants Promotion/Demotion",
    "text": "Participants Promotion/Demotion"
  },
  {
    "objectID": "LightningTalk.html#participants-feelings---statements-and-adjustments",
    "href": "LightningTalk.html#participants-feelings---statements-and-adjustments",
    "title": "Developing a Carpentries-style Machine Learning workshop",
    "section": "Participants‚Äô Feelings - Statements and Adjustments",
    "text": "Participants‚Äô Feelings - Statements and Adjustments\n\nobservation: At very end of the Runs, questions/participation/interest didn‚Äôt cease!\n‚ÄúPython lesson might be separated‚Äù\n\nRun #2: Python was removed from the curriculum\n\n‚Äúmore breaks‚Äù\n\nRun #2: better adherence to schedule\n\n‚Äústick to one coding interface‚Äù\n\nRun #2: only Colab, VSC etc. was linked to for post-workshop engagement\n\n\n\n\n\n\n\n\nNote\n\n\nAll statements are positive phrased; overall the results confirm a poasitive appreciation."
  },
  {
    "objectID": "ML-Recap.html#introduction-to-machine-learning-with-scikit-learn",
    "href": "ML-Recap.html#introduction-to-machine-learning-with-scikit-learn",
    "title": "ML-Carp Recap and Outlook",
    "section": "Introduction to Machine Learning with Scikit Learn",
    "text": "Introduction to Machine Learning with Scikit Learn\n\nNelis introduced us to the topic\nMike built on that\nRegression and Classification\nEnsemble methods, Clustering, Dimension reduction"
  },
  {
    "objectID": "ML-Recap.html#introduction-to-deep-learning",
    "href": "ML-Recap.html#introduction-to-deep-learning",
    "title": "ML-Carp Recap and Outlook",
    "section": "Introduction to Deep Learning",
    "text": "Introduction to Deep Learning\n\nNidhi switched from generic ML to Deep Learning (DL)\nSome aspects (there are more:)\n\nML: is non-stoachstic; similar if not the same result\nDL: non-convex and complex\nDL: only estimated/non-deterministic results/every run can differ a bit\nDL: of uses neural networks, but also DBN, VAEs, etc.\nDL: tends to use way more resources (CPU/GPU)\nML: Can still solve a lot of real-world issues using limilted resources"
  },
  {
    "objectID": "ML-Recap.html#workflows-for-heavier-computation",
    "href": "ML-Recap.html#workflows-for-heavier-computation",
    "title": "ML-Carp Recap and Outlook",
    "section": "Workflows for heavier computation",
    "text": "Workflows for heavier computation\n\nGoogle Colab vs.¬†locally installed Jupyter Notebooks or Plain Vanilla Python\n\nDo all use Colab ‚Äòin the real world‚Äô all the time? No!\n\nVSCode\nPython locally installed\n\nVirtual Environment\npip install\n\nusing GPU/Nectar/‚Ä¶"
  },
  {
    "objectID": "LaTeX101-24.html#what-is-it-for-1",
    "href": "LaTeX101-24.html#what-is-it-for-1",
    "title": "LaTeX 101",
    "section": "What is it for?",
    "text": "What is it for?\n\n\nReports\nForms\nRepeatable layouts & auto-generated content"
  },
  {
    "objectID": "LaTeX101-24.html#what-is-it-for-2",
    "href": "LaTeX101-24.html#what-is-it-for-2",
    "title": "LaTeX 101",
    "section": "What is it for?",
    "text": "What is it for?\n\n\nBeamer template for presentations\n\n\n\n\n\n\nNote\n\n\nthis website/presentation was built using Quarto and its RevealJS integration"
  },
  {
    "objectID": "LaTeX101-24.html#visualisations-in-tikz",
    "href": "LaTeX101-24.html#visualisations-in-tikz",
    "title": "LaTeX 101",
    "section": "Visualisations in TikZ",
    "text": "Visualisations in TikZ\nExample showing the power of the TikZ package"
  },
  {
    "objectID": "LaTeX101-24.html#visualisations-in-tikz--1",
    "href": "LaTeX101-24.html#visualisations-in-tikz--1",
    "title": "LaTeX 101",
    "section": "Visualisations in TikZ -1",
    "text": "Visualisations in TikZ -1\n Source"
  },
  {
    "objectID": "LaTeX101-24.html#visualisations-in-tikz--2",
    "href": "LaTeX101-24.html#visualisations-in-tikz--2",
    "title": "LaTeX 101",
    "section": "Visualisations in TikZ -2",
    "text": "Visualisations in TikZ -2\n Source"
  },
  {
    "objectID": "LaTeX101-24.html#visualisations-in-tikz--3",
    "href": "LaTeX101-24.html#visualisations-in-tikz--3",
    "title": "LaTeX 101",
    "section": "Visualisations in TikZ -3",
    "text": "Visualisations in TikZ -3\n Source"
  },
  {
    "objectID": "LaTeX101-24.html#visualisations-in-tikz--4",
    "href": "LaTeX101-24.html#visualisations-in-tikz--4",
    "title": "LaTeX 101",
    "section": "Visualisations in TikZ -4",
    "text": "Visualisations in TikZ -4\n Source"
  },
  {
    "objectID": "LaTeX101-24.html#easily-go-from-one-to-two-column-layouts",
    "href": "LaTeX101-24.html#easily-go-from-one-to-two-column-layouts",
    "title": "LaTeX 101",
    "section": "Easily go from one to two column layouts",
    "text": "Easily go from one to two column layouts\n\n\n\\documentclass[10pt,a4paper,onesided]{article} \n\\usepackage{lipsum}\n\\begin{document}\n  \\section{My Title}\n  \\subsection{Sub-Section}\n  \\textbf{Printing 1 to 3 paragraphs}\\\\\n  \\lipsum[1-3]\n  \\subsection{Sub-Section}\n  \\lipsum[1]\n\\end{document}\nNote that: ‚Ä¶onesided‚Ä¶ \n\n#| \\documentclass[10pt,a4paper,twocolumn]{article} \n\\usepackage{lipsum}\n\\begin{document}\n  \\section{My Title}\n  \\subsection{Sub-Section}\n  \\textbf{Printing 1 to 3 paragraphs}\\\\\n  \\lipsum[1-3]\n  \\subsection{Sub-Section}\n  \\lipsum[1]\n\\end{document}\nNote that: ‚Ä¶twocolumn‚Ä¶"
  },
  {
    "objectID": "LaTeX101-24.html#mathsformulae",
    "href": "LaTeX101-24.html#mathsformulae",
    "title": "LaTeX 101",
    "section": "Maths/Formulae",
    "text": "Maths/Formulae"
  },
  {
    "objectID": "LaTeX101-24.html#external-files",
    "href": "LaTeX101-24.html#external-files",
    "title": "LaTeX 101",
    "section": "External Files",
    "text": "External Files\n\nExternal files are referenced\n\ne.g.¬†an Images folder.\nupdating files (same file name) come into effect automatically/quickly (after recompiling)\nWhile doint that, consider a version control mechanism such as GitHub  to avoid data loss\n\nSimilarly: imported data (often in the csv file format) which you can get to automatically update tables\nEven layouts can be changed plug and play\n\n\n\n\n\n\n\nWarning\n\n\nHow would you do this is a MS Word document? How can you make sure that you updated all and didn‚Äôt miss one? There are workardounds, but they are not as elegant as in \\(\\LaTeX\\)"
  },
  {
    "objectID": "LaTeX101-24.html#preamble",
    "href": "LaTeX101-24.html#preamble",
    "title": "LaTeX 101",
    "section": "Preamble",
    "text": "Preamble\n\nsimilar to coding:\n\nyou start with importing relevant libraries (things others did to make your life easier)\nand definitions (for example, colours)\n\n\n\\documentclass[twoside,openright,a4paper]\n\n\\usepackage[usenames, dvipsnames, table]{xcolor}\n\n\\addbibresource{references.bib}\n\n\\definecolor{uoadarkblue}{RGB}{0, 70, 127}"
  },
  {
    "objectID": "LaTeX101-24.html#main-body",
    "href": "LaTeX101-24.html#main-body",
    "title": "LaTeX 101",
    "section": "Main body",
    "text": "Main body\nYou can either\n\nwrite all your document in one text file (with the file extension *.tex)\n\noften better practice: \\include command to include chapters\n\n\\(\\LaTeX\\) commands usually start with the backslash character \\...\nas in all coding: Details matter: close brackets you opened, etc.\n\\(\\LaTeX\\) is mostely whitespace-insensitive, this means you can write your .tex document without having to worry about empty lines, etc. This also means, if you want to include empty lines, you have to enforce them\n\n\\\\ (two backslashes)\n\\newline\n\\hfill \\break\nsee also\n\n\n\\include{Titlepage}\n\\part{Background}\n\\include{Chapters/Intro}"
  },
  {
    "objectID": "LaTeX101-24.html#references-appendices-etc.",
    "href": "LaTeX101-24.html#references-appendices-etc.",
    "title": "LaTeX 101",
    "section": "References, Appendices, etc.",
    "text": "References, Appendices, etc.\n\nall of these can be ingested (reference to external files) in the preamble\nIt‚Äôs fair to consider this a strong-suit of \\(\\LaTeX\\)\n\n\\section{Test}\\label{sec:test}\nSome text\n\\begin{equation}\n  e = m c^2\n  \\label{eqn:emc}\n\\end{equation}\n\n\\subsection{Discussion}\nAs we can see in Equation \\ref{eqn:emc} in Section \\ref{sec:test}..."
  },
  {
    "objectID": "LaTeX101-24.html#how-to-get-latex---the-core",
    "href": "LaTeX101-24.html#how-to-get-latex---the-core",
    "title": "LaTeX 101",
    "section": "How to get \\(\\LaTeX\\) - the core",
    "text": "How to get \\(\\LaTeX\\) - the core\n\n\n\n\n\n\nTip\n\n\nIdea: As software-agnostic as possible\n\n\n\n\nDownload a \\(\\LaTeX\\) distribution, for example MiKTeX\ninstall pandoc\nuse any texteditor  TextEdit,  Notepad,,  various\na generic IDE, such as VSCode\non the commandline: type pandoc -i ~/Desktop/myWritings.tex -o ~/Desktop/MyRenderedLaTeX.pdf\ninspect your neatly renedered document"
  },
  {
    "objectID": "LaTeX101-24.html#how-to-get-latex---special-editors",
    "href": "LaTeX101-24.html#how-to-get-latex---special-editors",
    "title": "LaTeX 101",
    "section": "How to get \\(\\LaTeX\\) - special editors",
    "text": "How to get \\(\\LaTeX\\) - special editors\n\n\n\n\n\n\nTip\n\n\nIdea: local installation and a specialised editor\n\n\n\n\nTexifier\nTeXLive\nTeXStudio\nTeXMaker"
  },
  {
    "objectID": "LaTeX101-24.html#how-to-get-latex---in-the-browser",
    "href": "LaTeX101-24.html#how-to-get-latex---in-the-browser",
    "title": "LaTeX 101",
    "section": "How to get \\(\\LaTeX\\) - In the browser",
    "text": "How to get \\(\\LaTeX\\) - In the browser\n\nOverleaf is quote famous for ‚Äúbringing \\(\\LaTeX\\) to the masses‚Äù\nA pro and con at the same time: It runs in the cloud, you don‚Äôt need to install a \\(\\LaTeX\\) distribution, special editor, etc.\nRecently, they added ‚ÄúOverleaf On-Premises‚Äù to circumvent privacy challenges\nthere is a free plan which might be a good fit for beginners or if it is just you wokring on a dcument\nthere are paid plans, including student plans which are currently NZD109/year\n\nThe main advantages:\n\nInvite collaborators, so work on the same document at the same time\nHave a similar tracking mechanism as MS Word‚Äôs Track Changes\nSync to Dropbox, GitHub, etc.\n\n\nUniversity of Auckland ABI staff/students get Overleaf premium free"
  },
  {
    "objectID": "LaTeX101-24.html#how-to-get-latex---the-meta-version",
    "href": "LaTeX101-24.html#how-to-get-latex---the-meta-version",
    "title": "LaTeX 101",
    "section": "How to get \\(\\LaTeX\\) - The meta version",
    "text": "How to get \\(\\LaTeX\\) - The meta version\nQuarto can be considered one level above in terms of abstraction \n\n\\(\\LaTeX\\) is just one of its output, the other benefit is a direct integration with Python, R, Julia, Observable\nyou can write in markdown syntax (.md) so for example **my text** (md notation) as oppsed to \\textbf{my text}\nthe integration with code means you won‚Äôt have to copy-paste results back and forth\n\nthis point can‚Äôt be stressed enough! You are so likely to forget updating a plot\nyou also get reproducability, because it isn‚Äôt just a screen shot that is integrated into your document &lt;!‚Äì (There are approaches where you can get some (rudimentary) Python code into LaTeX, even into Overleaf, but these are mainly for handling several files (batch processing) keeping track of Python version- Coding colaborators can contribute via a Git workflow\n\nCommunicate results to non-coding collaborators using git (e.g., GitHub)"
  },
  {
    "objectID": "LaTeX101-24.html#tables",
    "href": "LaTeX101-24.html#tables",
    "title": "LaTeX 101",
    "section": "Tables",
    "text": "Tables\n\n\n\nA simple table in \\(\\LaTeX\\) syntax:\n\n\\begin{table}[]\n\\caption{My Example Table}\n\\label{tab:my-table}\n\\begin{tabular}{|l|l|l|l|l|}\n\\hline\ncountry     & 1999   & 2000   &  &  \\\\ \\hline\nAfghanistan & 745    & 2666   &  &  \\\\ \\hline\nBrazil      & 37737  & 80488  &  &  \\\\ \\hline\nChina       & 212258 & 213766 &  &  \\\\ \\hline\n\\end{tabular}\n\\end{table}\n\n\nAlternatively using markdown syntax:\n\n| country     | 1999   | 2000   |   |   |\n|-------------|--------|--------|---|---|\n| Afghanistan | 745    | 2666   |   |   |\n| Brazil      | 37737  | 80488  |   |   |\n| China       | 212258 | 213766 |   |   |\n\n\nTo be honest:\n\nBoth are a pain to format by hand\nYou shouldn‚Äôt work with your data in these. These are for publishing only\n\nTablesGenerator and or LaTeXTables can help you with that\nIf applicable(!!!): ChatGPT etc. do a pretty decent job; make sure you are allowed (multi-stakeholder) to use them"
  },
  {
    "objectID": "LaTeX101-24.html#latex-guides-and-references",
    "href": "LaTeX101-24.html#latex-guides-and-references",
    "title": "LaTeX 101",
    "section": "\\(\\LaTeX\\) guides and references",
    "text": "\\(\\LaTeX\\) guides and references\nThe Not So Short Introduction To Latex\nOverleaf tutorials\nLatex Reference (also as a website)\nWiki-book"
  },
  {
    "objectID": "LaTeX101.html#visualisations-in-tikz",
    "href": "LaTeX101.html#visualisations-in-tikz",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Visualisations in TikZ",
    "text": "Visualisations in TikZ\nExample showing the power of the TikZ package"
  },
  {
    "objectID": "LaTeX101.html#visualisations-in-tikz--1",
    "href": "LaTeX101.html#visualisations-in-tikz--1",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Visualisations in TikZ -1",
    "text": "Visualisations in TikZ -1\n Source"
  },
  {
    "objectID": "LaTeX101.html#visualisations-in-tikz--2",
    "href": "LaTeX101.html#visualisations-in-tikz--2",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Visualisations in TikZ -2",
    "text": "Visualisations in TikZ -2\n Source"
  },
  {
    "objectID": "LaTeX101.html#visualisations-in-tikz--3",
    "href": "LaTeX101.html#visualisations-in-tikz--3",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Visualisations in TikZ -3",
    "text": "Visualisations in TikZ -3\n Source"
  },
  {
    "objectID": "LaTeX101.html#visualisations-in-tikz--4",
    "href": "LaTeX101.html#visualisations-in-tikz--4",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Visualisations in TikZ -4",
    "text": "Visualisations in TikZ -4\n Source"
  },
  {
    "objectID": "LaTeX101.html#easily-go-from-one-to-two-column-layouts",
    "href": "LaTeX101.html#easily-go-from-one-to-two-column-layouts",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Easily go from one to two column layouts",
    "text": "Easily go from one to two column layouts\n\n\n\\documentclass[10pt,a4paper,onesided]{article} \n\\usepackage{lipsum}\n\\begin{document}\n  \\section{My Title}\n  \\subsection{Sub-Section}\n  \\textbf{Printing 1 to 3 paragraphs}\\\\\n  \\lipsum[1-3]\n  \\subsection{Sub-Section}\n  \\lipsum[1]\n\\end{document}\nNote that: ‚Ä¶onesided‚Ä¶ \n\n#| \\documentclass[10pt,a4paper,twocolumn]{article} \n\\usepackage{lipsum}\n\\begin{document}\n  \\section{My Title}\n  \\subsection{Sub-Section}\n  \\textbf{Printing 1 to 3 paragraphs}\\\\\n  \\lipsum[1-3]\n  \\subsection{Sub-Section}\n  \\lipsum[1]\n\\end{document}\nNote that: ‚Ä¶twocolumn‚Ä¶"
  },
  {
    "objectID": "LaTeX101.html#mathsformulae",
    "href": "LaTeX101.html#mathsformulae",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Maths/Formulae",
    "text": "Maths/Formulae"
  },
  {
    "objectID": "LaTeX101.html#external-files",
    "href": "LaTeX101.html#external-files",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "External Files",
    "text": "External Files\n\nYou (usuall) reference external files; this means you might have a ‚ÄòImages‚Äô folder. All updates (while maintaining the file name) come into effect quickly (after recompiling); consider a version control mechanism such as GitHub to avoid data loss\nThis also works for imported data (often in the csv file format) which you can get to automatically update tables\nEven layouts can be changed\n\nWorkflow for changing things in citations (Zotero) or getting a citation from a paper (three steps and done), backed up to GitHub, don‚Äôt worry\nUpdate a picture to the latest version, keep the name, don‚Äôt worry about overwriting, because you have it on GitHub\nBecause of LaTeXIt knowing the syntax can help you with creating vis. for your PowerPoint, Slides, ‚Ä¶ Presentation\nSyntax highlighting for code\nChange a caption on several figures, update the ToC,‚Ä¶"
  },
  {
    "objectID": "LaTeX101.html#advantages",
    "href": "LaTeX101.html#advantages",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Advantages",
    "text": "Advantages\n\n\n\n\n\n\nNote\n\n\nThere is a trade-off between time invested upfront (learning \\(\\LaTeX\\) etc. vs.¬†and time saved in the long-run. As many of you might work on their PhD thesises, this time balance one day before the deadline vs.¬†some hours or days can‚Äôt be traded-off 1:1\n\n\n\n\n(good) \\(\\LaTeX\\) output looks epic (at least in most cases)\n\nit decides where pictures are placed\nmaths is neatly rendered\nhow line-breaks happen (justify text is using a dictionary for line-breaks, unlike many wysiwyg editors)\nmulti-column layouts on one page"
  },
  {
    "objectID": "LaTeX101.html#advantages---continued",
    "href": "LaTeX101.html#advantages---continued",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Advantages - continued",
    "text": "Advantages - continued\n\nit is free and not tied to any big corporation, you can often write in any text editor, browser etc.\nit is no closed source file (unlike a .docx or so) this means we can use Git(Hub) EXAMPLE and other version control systems (we can run things like a diff on it, EXAMPLE CODE GOES HERE)\n\nno proprietary software that\n\nmight disappear from the market\ncharges you an arm and a leg especially over time with a subscription model (yes, I am looking at you, Adobe)\nmeans you can keep this compeltely offline/local/no-cloud, etc. good for Ethics Approvals and sensitive data, ‚Ä¶\n\n\nyou can mostly get outputs to several outputs with altering a few lines (vs.¬†clicking on every slide or here and there)"
  },
  {
    "objectID": "LaTeX101.html#advantages---continued-1",
    "href": "LaTeX101.html#advantages---continued-1",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Advantages - continued",
    "text": "Advantages - continued\n\nyou can customise it heavily\nyou can have inline comments (for future you, for your supervisor, to toggle things on/off)\nIf you ingest some code, tables, data, a lot of figures ResBaz Workshop Python for image manipulation and repeatable research pipelines, you will learn to love \\(\\LaTeX\\)\nReferencing is quite easy, especially if paired with a reference manager such as Zotero, see ResBaz session Managing References With Zotero\nMaths! \\(f_{c}=z^{2}+c\\) AND Mathpix Snipping\nPlotting (again some learning curve, but no Excel to Word to something schenanigans where you might miss out the latest version of a file and try to publish something wrong)\nsame goes for citations, referencing figures, placing figures (yes, you can specify that it shall be right there where you want it, but you can also let \\(\\LaTeX\\) work it‚Äôs magic)\nPortability: LaTeX documents are portable and can be easily converted to other formats, such as PDF, HTML, or EPUB."
  },
  {
    "objectID": "LaTeX101.html#advantages---continued-2",
    "href": "LaTeX101.html#advantages---continued-2",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Advantages - continued",
    "text": "Advantages - continued\nSymbols often render very neatly, sometimes workarounds are needed\nM\\={a}ori \nFor Macrons a more advanced approach is described here, as Unicode is mostly used, you can type MƒÅori (so on a Mac use the long-press option ƒÅ to write MƒÅori or change the keyboard style) or copy-paste such characters."
  },
  {
    "objectID": "LaTeX101.html#disadvantages",
    "href": "LaTeX101.html#disadvantages",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nit takes time to learn (Overleaf and other more relevant UI etc. make it easier)\nit can be very fiddely (if you want specifics with tables, or placing images)\nthe collaboration features are quite limited out of the box, yes, a lot can be done (see Eirian), but that mostly requires you to a) bring/acquire some coding knowledge, b) invest time; here, MS Word Clearly wins\nplugins such as Grammarly don‚Äôt work ootb, for VSCode, you can integrate these as an Extension, on Overleaf there is a buggy workaround"
  },
  {
    "objectID": "LaTeX101.html#preamble",
    "href": "LaTeX101.html#preamble",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Preamble",
    "text": "Preamble\nThis is similar to programming where you start with importing relevant libraries (things others did to make your life easier) and definitions (for example, colours)\n\\documentclass[twoside,openright,a4paper]\n\n\\usepackage[usenames, dvipsnames, table]{xcolor}\n\n\\addbibresource{references.bib}\n\n\\definecolor{uoadarkblue}{RGB}{0, 70, 127}"
  },
  {
    "objectID": "LaTeX101.html#main-body",
    "href": "LaTeX101.html#main-body",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Main body",
    "text": "Main body\nYou can either - write all your document in one text file (with the file extension *.tex) - \\(\\LaTeX\\) commands usually start with the backslash character - as in all coding, it is important to close brackets that you have opened and to be quite picky with the details - \\(\\LaTeX\\) is mostely whitespace-insensitive, this means you can write your .tex document without having to worry about empty lines, etc. This also means, if you want to include empty lines, you have to enforce them - \\\\ (two backslashes) - \\newline - \\hfill \\break - see also - It is good practice not to create one huge .tex file but to use the \\include command to include chapters\n\\include{Titlepage}\n\\part{Background}\n\\include{Chapters/Intro}"
  },
  {
    "objectID": "LaTeX101.html#references-appendices-etc.",
    "href": "LaTeX101.html#references-appendices-etc.",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "References, Appendices, etc.",
    "text": "References, Appendices, etc.\n\nall of these can be ingested (reference to external files) in the preamble\nIt‚Äôs fair to consider this a strong-suit of \\(\\LaTeX\\)\ndetails exceed the scope of this introduction; more in-depth ResBaz sessions are offered (see Section¬†10) and you can refer to the template provided"
  },
  {
    "objectID": "LaTeX101.html#how-to-get-latex---the-core",
    "href": "LaTeX101.html#how-to-get-latex---the-core",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "How to get \\(\\LaTeX\\) - the core",
    "text": "How to get \\(\\LaTeX\\) - the core\nIdea: As software-agnostic as possible - Download a \\(\\LaTeX\\) distribution, for example MiKTeX - install pandoc - use any texteditor - Windows: - Notepad - Mac: - TextEdit - Linux: - various - Cross-Platform: - VSCode - Sublime - on the commandline: type pandoc -i ~/Desktop/myWritings.tex -o ~/Desktop/MyRenderedLaTeX.pdf - inspect your neatly renedered document"
  },
  {
    "objectID": "LaTeX101.html#how-to-get-latex---special-editors",
    "href": "LaTeX101.html#how-to-get-latex---special-editors",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "How to get \\(\\LaTeX\\) - special editors",
    "text": "How to get \\(\\LaTeX\\) - special editors\nThe idea is to have a local installation and a specialised editor - Texifier - TeXLive - TeXStudio - TeXMaker"
  },
  {
    "objectID": "LaTeX101.html#how-to-get-latex---in-the-browser",
    "href": "LaTeX101.html#how-to-get-latex---in-the-browser",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "How to get \\(\\LaTeX\\) - In the browser",
    "text": "How to get \\(\\LaTeX\\) - In the browser\n\nOverleaf is quote famous for bringing $to the masses\nA pro and con at the same time: It runs in the cloud, you don‚Äôt need to install a \\(\\LaTeX\\) distribution, special editor, etc.\nRecently, they added ‚ÄúOverleaf On-Premises‚Äù to circumvent privacy challenges\nthere is a free plan which might be a good fit for beginners or if it is just you wokring on a dcument\nthere are paid plans, including student plans which are currently NZD109/year\n\nThe main advantages:\n\nInvite collaborators, so work on the same document at the same time\nHave a similar tracking mechanism as MS Word‚Äôs Track Changes\nSync to Dropbox, GitHub, etc.\n\n\nUoA Bioengineering staff/students get Overleaf premium free ALTERNATVIELY: There is another ResBaz session: Stop Paying for Free Software"
  },
  {
    "objectID": "LaTeX101.html#how-to-get-latex---the-meta-version",
    "href": "LaTeX101.html#how-to-get-latex---the-meta-version",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "How to get \\(\\LaTeX\\) - The meta version",
    "text": "How to get \\(\\LaTeX\\) - The meta version\nQuarto can be considered one level above in terms of abstraction \n\n\\(\\LaTeX\\) is just one of its output, the other benefit is a direct integration with Python, R, Julia, Observable\nyou can write in markdown syntax (.md) so for example **my text** (md notation) as oppsed to \\textbf{my text}\nthe integration with code means you won‚Äôt have to copy-paste results back and forth\n\nthis point can‚Äôt be stressed enough! You are so likely to forget updating a plot\nyou also get reproducability, because it isn‚Äôt just a screen shot that is integrated into your document &lt;!‚Äì (There are approaches where you can get some (rudimentary) Python code into LaTeX, even into Overleaf, but these are mainly for handling several files (batch processing) keeping track of Python version- Coding colaborators can contribute via a Git workflow\n\nCommunicate results to non-coding collaborators using git (e.g., GitHub)\n\n\n\n\n\n\n\nOn a side-note\n\n\nThis deck of slides (based on RevealJS, it can also handle a lot of code."
  },
  {
    "objectID": "LaTeX101.html#tables",
    "href": "LaTeX101.html#tables",
    "title": "LaTeX 101 - Don‚Äôt be scared",
    "section": "Tables",
    "text": "Tables\n\n\n\nA simple table in \\(\\LaTeX\\) syntax:\n\n\\begin{table}[]\n\\caption{My Example Table}\n\\label{tab:my-table}\n\\begin{tabular}{|l|l|l|l|l|}\n\\hline\ncountry     & 1999   & 2000   &  &  \\\\ \\hline\nAfghanistan & 745    & 2666   &  &  \\\\ \\hline\nBrazil      & 37737  & 80488  &  &  \\\\ \\hline\nChina       & 212258 & 213766 &  &  \\\\ \\hline\n\\end{tabular}\n\\end{table}\n\n\nAlternatively using markdown syntax:\n\n| country     | 1999   | 2000   |   |   |\n|-------------|--------|--------|---|---|\n| Afghanistan | 745    | 2666   |   |   |\n| Brazil      | 37737  | 80488  |   |   |\n| China       | 212258 | 213766 |   |   |\n\n\nTo be honest:\n\nBoth are a pain to format by hand\nYou shouldn‚Äôt work with your data in these. These are for publishing only.\nSome see spreadsheet software (MSExcel, Google Sheets, etc.) just suited for data entry, Python, R, OpenRefine, etc. are better alternatives whose learning curve isn‚Äôt as steep as you might expect and relevant sessions are also provided at this year‚Äôs ResBaz (see pointers)"
  },
  {
    "objectID": "DataWorkflows2024.html",
    "href": "DataWorkflows2024.html",
    "title": "Goals for today",
    "section": "",
    "text": "This session is mostly about showing efficient means of working with data\n\nfor example, the Python session on Wednesday\n\nThe selection of a geospatial dataset is mostly because it\n\ncan be easily visualised and (hopefully) understodd\nsophisticated libraries exist; geopandas and folium that can be used to work with geospatial data\n\nsimilar libraries exist for various research disciplines, so go out and explore!\n\n\nOverall, we will\n\ninstall Python\ninstall Microsoft Visual Studio Code\n(install Jupyter Notebook)\npip install geopandas and other libraries\nuse git for version control; GitHub as our provider for this\n\nfor more details see https://www.eventbrite.co.nz/e/introduction-to-version-control-with-git-tickets-908002348467\n\ndownload a dataset\nuse folium to visualise this data\n(ChatGPT‚Äôs take on leaflet vs.¬†folium vs.¬†geopandas)"
  },
  {
    "objectID": "DataWorkflows2024.html#python-because-it-is",
    "href": "DataWorkflows2024.html#python-because-it-is",
    "title": "Goals for today",
    "section": "Python because it is‚Ä¶",
    "text": "Python because it is‚Ä¶\n\n‚Ä¶ relatively easy to learn and use\n‚Ä¶ general-purpose programming language, which means it can be used to build just about anything"
  },
  {
    "objectID": "DataWorkflows2024.html#we-now-use-geopandas",
    "href": "DataWorkflows2024.html#we-now-use-geopandas",
    "title": "Goals for today",
    "section": "We now use Geopandas",
    "text": "We now use Geopandas\n\nthe gpd is a special kind of pandas DataFrame\nthe .dropna is a means of filtering data (here, these are rows) that contain a n/a ‚Äî in other words: A row that has elements with no data, that would otherwise give us challenges\n\non a bigger picture perspective: It is hard to calculate the average of a column if there are missing values in it; avg (2+4+NaN) = NaN\nthis is only applied to the geometry column, which is the column that contains the geospatial data\n\n\n\n\nsa2 = gpd.read_file(\"statistical-area-2-2023-generalised_simplified_22.3%.zip\").dropna(subset=\"geometry\")\nsa2\n\n\n\n\n\n\n\n\nSA22023_V1\nSA22023__1\nSA22023__2\nLAND_AREA_\nAREA_SQ_KM\nShape_Leng\ngeometry\n\n\n\n\n0\n100100\nNorth Cape\nNorth Cape\n829.188012\n829.188012\n4.160392e+05\nMULTIPOLYGON (((1614055.808 6154067.023, 16141...\n\n\n1\n100200\nRangaunu Harbour\nRangaunu Harbour\n274.004295\n274.004295\n1.490891e+05\nMULTIPOLYGON (((1624166.328 6127258.658, 16243...\n\n\n2\n100301\nInlets Far North District\nInlets Far North District\n0.000000\n623.222037\n1.349364e+06\nMULTIPOLYGON (((1620023.410 6084653.062, 16197...\n\n\n3\n100400\nKarikari Peninsula\nKarikari Peninsula\n174.440751\n174.440751\n1.401491e+05\nMULTIPOLYGON (((1626838.499 6126965.133, 16270...\n\n\n4\n100500\nTangonge\nTangonge\n177.182117\n177.182117\n1.014669e+05\nPOLYGON ((1623516.265 6119580.907, 1623492.213...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2381\n363600\nOceanic Marlborough Region\nOceanic Marlborough Region\n0.000000\n5204.239555\n6.030516e+05\nPOLYGON ((1735069.340 5471565.641, 1731082.409...\n\n\n2382\n363700\nOceanic Southland Region\nOceanic Southland Region\n0.000000\n22404.339718\n2.702862e+06\nPOLYGON ((1201178.956 5079126.036, 1201206.109...\n\n\n2383\n363800\nOceanic Canterbury Region\nOceanic Canterbury Region\n0.000000\n11441.928693\n1.176106e+06\nPOLYGON ((1686900.717 5353231.610, 1704528.061...\n\n\n2384\n363900\nOceanic Otago Region\nOceanic Otago Region\n0.000000\n6538.077281\n7.359200e+05\nPOLYGON ((1453579.263 5021995.144, 1474465.101...\n\n\n2385\n364000\nMotunau Island\nMotunau Island\n0.081474\n0.081474\n1.427156e+03\nPOLYGON ((1606233.915 5232188.150, 1606183.115...\n\n\n\n\n2379 rows √ó 7 columns"
  },
  {
    "objectID": "DataWorkflows2024.html#lets-perform-some-sanity-checks",
    "href": "DataWorkflows2024.html#lets-perform-some-sanity-checks",
    "title": "Goals for today",
    "section": "let‚Äôs perform some sanity checks",
    "text": "let‚Äôs perform some sanity checks\n\n# give me only the rows in sa2 that have a geometry of NaN\nsa2[sa2[\"geometry\"].isna()]\n\n\n\n\n\n\n\n\n\nSA22023_V1\nSA22023__1\nSA22023__2\nLAND_AREA_\nAREA_SQ_KM\nShape_Leng\ngeometry\n\n\n\n\n\n\n\n\n\n\n# only show me rows where SA22023__1 and SA22023__2 differ\nsa2[sa2[\"SA22023__1\"] != sa2[\"SA22023__2\"]]\n\n\n\n\n\n\n\n\nSA22023_V1\nSA22023__1\nSA22023__2\nLAND_AREA_\nAREA_SQ_KM\nShape_Leng\ngeometry\n\n\n\n\n10\n104301\n√Ö≈ípua (Far North District)\nOpua (Far North District)\n5.602473\n5.827312\n19213.437576\nPOLYGON ((1699472.895 6094086.681, 1699528.640...\n\n\n14\n104800\nMangakahia-H√Ö¬´kerenui\nMangakahia-Hukerenui\n659.254330\n659.254330\n183365.297157\nPOLYGON ((1709183.206 6068629.847, 1709173.331...\n\n\n19\n105400\nMaungat√Ñ?pere\nMaungatapere\n174.482190\n174.482190\n93344.845747\nPOLYGON ((1711760.225 6046448.026, 1711747.134...\n\n\n20\n105601\nMatapouri-Tutuk√Ñ?k√Ñ?\nMatapouri-Tutukaka\n78.527938\n78.587007\n86800.477007\nMULTIPOLYGON (((1740046.334 6057828.894, 17399...\n\n\n43\n108000\nP√Ñ?taua\nPataua\n128.707987\n128.707987\n129154.856928\nMULTIPOLYGON (((1740486.853 6046295.860, 17405...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2265\n347000\nW√Ñ?naka Central\nWanaka Central\n7.562054\n7.562054\n12758.648935\nPOLYGON ((1296155.366 5043593.460, 1296353.267...\n\n\n2267\n347101\nLake H√Ñ?wea\nLake Hawea\n3.655589\n3.655589\n9016.577926\nPOLYGON ((1302855.368 5051689.464, 1302774.822...\n\n\n2335\n357200\nInland water Lake Te √Ñ‚Ç¨nau\nInland water Lake Te Anau\n0.000000\n344.402829\n361810.765779\nPOLYGON ((1199680.502 5012394.655, 1199729.683...\n\n\n2341\n357501\nTe √Ñ‚Ç¨nau\nTe Anau\n6.637305\n6.657040\n12967.743524\nPOLYGON ((1186662.007 4956066.127, 1186763.928...\n\n\n2346\n358000\n√Ö≈íhai-Nightcaps\nOhai-Nightcaps\n948.798919\n948.798919\n174165.196492\nPOLYGON ((1232653.066 4911665.243, 1229777.053...\n\n\n\n\n175 rows √ó 7 columns\n\n\n\nnow it becomes apparent what the difference might be; let‚Äôs have a look at the original dataset‚Äôs column names: - SA22023_V1_00_NAME - SA22023_V1_00_NAME_ASCII So two ways how characters are encoded, this is a common issue in data processing and by giving both options, this facilites the process\nWe do not want to include the Chatam Islands, as they are not part of the main landmass of New Zealand and only under 800 people live there.\n\n\n\nalt\n\n\nWe want to make sure that we don‚Äôt have empty SA2 (that is unlikely but for other ‚Äòresolutions‚Äô/approaches of classifying geospatial data, there might be a use for that, e.g.¬†Marine Buoy Locations Dataset)\n\n# only show me rows where LAND_AREA_ column is zero\nsa2[sa2[\"LAND_AREA_\"] == 0]\n\n\n\n\n\n\n\n\nSA22023_V1\nSA22023__1\nSA22023__2\nLAND_AREA_\nAREA_SQ_KM\nShape_Leng\ngeometry\n\n\n\n\n2\n100301\nInlets Far North District\nInlets Far North District\n0.0\n623.222037\n1.349364e+06\nMULTIPOLYGON (((1620023.410 6084653.062, 16197...\n\n\n16\n105001\nInlets other Whangarei District\nInlets other Whangarei District\n0.0\n38.949878\n2.012673e+05\nMULTIPOLYGON (((1737958.662 6046745.046, 17380...\n\n\n24\n111000\nOceanic Auckland Region West\nOceanic Auckland Region West\n0.0\n2384.034569\n2.793983e+05\nPOLYGON ((1724020.922 5929713.851, 1724095.069...\n\n\n30\n112001\nInlets other Auckland\nInlets other Auckland\n0.0\n122.490416\n5.958464e+05\nMULTIPOLYGON (((1791662.172 5909541.528, 17916...\n\n\n44\n108400\nInlet Whang√Ñ?rei Harbour\nInlet Whangarei Harbour\n0.0\n103.520564\n1.658690e+05\nPOLYGON ((1722383.512 6044397.233, 1722876.556...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2380\n363500\nOceanic Nelson Region\nOceanic Nelson Region\n0.0\n787.574671\n1.537628e+05\nPOLYGON ((1630452.435 5482785.080, 1638439.661...\n\n\n2381\n363600\nOceanic Marlborough Region\nOceanic Marlborough Region\n0.0\n5204.239555\n6.030516e+05\nPOLYGON ((1735069.340 5471565.641, 1731082.409...\n\n\n2382\n363700\nOceanic Southland Region\nOceanic Southland Region\n0.0\n22404.339718\n2.702862e+06\nPOLYGON ((1201178.956 5079126.036, 1201206.109...\n\n\n2383\n363800\nOceanic Canterbury Region\nOceanic Canterbury Region\n0.0\n11441.928693\n1.176106e+06\nPOLYGON ((1686900.717 5353231.610, 1704528.061...\n\n\n2384\n363900\nOceanic Otago Region\nOceanic Otago Region\n0.0\n6538.077281\n7.359200e+05\nPOLYGON ((1453579.263 5021995.144, 1474465.101...\n\n\n\n\n83 rows √ó 7 columns\n\n\n\nwe can combine this into one prompt and see the result\n\nsa2 = sa2[(sa2.SA22023__1 != \"Chatham Islands\") & (sa2.LAND_AREA_ &gt; 0)].copy()\nsa2\n\n\n\n\n\n\n\n\nSA22023_V1\nSA22023__1\nSA22023__2\nLAND_AREA_\nAREA_SQ_KM\nShape_Leng\ngeometry\n\n\n\n\n0\n100100\nNorth Cape\nNorth Cape\n829.188012\n829.188012\n416039.151064\nMULTIPOLYGON (((1614055.808 6154067.023, 16141...\n\n\n1\n100200\nRangaunu Harbour\nRangaunu Harbour\n274.004295\n274.004295\n149089.110095\nMULTIPOLYGON (((1624166.328 6127258.658, 16243...\n\n\n3\n100400\nKarikari Peninsula\nKarikari Peninsula\n174.440751\n174.440751\n140149.099270\nMULTIPOLYGON (((1626838.499 6126965.133, 16270...\n\n\n4\n100500\nTangonge\nTangonge\n177.182117\n177.182117\n101466.900183\nPOLYGON ((1623516.265 6119580.907, 1623492.213...\n\n\n5\n100900\nRangitihi\nRangitihi\n84.539982\n84.539982\n60636.302194\nPOLYGON ((1629314.862 6117970.968, 1629371.783...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2374\n362601\nHeidelberg\nHeidelberg\n1.308968\n1.308968\n5367.870180\nPOLYGON ((1245892.259 4848174.153, 1245922.973...\n\n\n2375\n363001\nClifton-Kew\nClifton-Kew\n3.770832\n3.770832\n11890.253381\nPOLYGON ((1243666.689 4847254.124, 1243677.447...\n\n\n2376\n363100\nWoodend-Greenhills\nWoodend-Greenhills\n173.600766\n173.600766\n166674.352079\nMULTIPOLYGON (((1248612.765 4823630.510, 12486...\n\n\n2378\n363301\nBluff\nBluff\n10.136949\n10.290040\n23162.004392\nPOLYGON ((1244729.237 4827495.819, 1244667.973...\n\n\n2385\n364000\nMotunau Island\nMotunau Island\n0.081474\n0.081474\n1427.156234\nPOLYGON ((1606233.915 5232188.150, 1606183.115...\n\n\n\n\n2295 rows √ó 7 columns"
  },
  {
    "objectID": "DataWorkflows2024.html#this-brings-us-to-a-common-challenge-with-combining-datasets-from-different-sources",
    "href": "DataWorkflows2024.html#this-brings-us-to-a-common-challenge-with-combining-datasets-from-different-sources",
    "title": "Goals for today",
    "section": "this brings us to a common challenge with combining datasets from different sources",
    "text": "this brings us to a common challenge with combining datasets from different sources\n\nthe SA2 dataset has relevant data split into several columns\n\nSA22023_V1 is a predefined ID; this is a common practice in data processing! It is unique\nSA22023__1 is easily understandable name\nSA22023__2 is the same name but in ASCII encoding (special characters matter, remmeber?)\n\nthe population dataset has similar information combined in the AREA column\nit starts with the numeric code\nthen the human readable name"
  },
  {
    "objectID": "DataWorkflows2024.html#do-you-have-any-idea-how-we-can-efficiently-work-with-such-datasets",
    "href": "DataWorkflows2024.html#do-you-have-any-idea-how-we-can-efficiently-work-with-such-datasets",
    "title": "Goals for today",
    "section": "Do you have any idea how we can efficiently work with such datasets?",
    "text": "Do you have any idea how we can efficiently work with such datasets?\nZOOM POLL\n\nfor now, we assume that the unique idea is a lot easier to find the corresponding data in the two datasets\nif someone has already defined such a ‚Äòkey‚Äô, we don‚Äôt have to worry about the encoding of the name (special characters and all)\n\n\n# Extract ID from Area col\npopulation['SA2'] = population['Area'].str.extract(r'(\\d+)')\npopulation\n\n\n\n\n\n\n\n\nArea\n1996\n2001\n2006\n2013\n2018\n2019\n2020\n2021\n2022\nSA2\n\n\n\n\n0\n100100 North Cape\n1710.0\n1520.0\n1380.0\n1470.0\n1660.0\n1690.0\n1750.0\n1800.0\n1820.0\n100100\n\n\n1\n100200 Rangaunu Harbour\n2050.0\n2100.0\n2070.0\n2200.0\n2410.0\n2470.0\n2580.0\n2620.0\n2640.0\n100200\n\n\n2\n100300 Inlets Far North district\n190.0\n140.0\n70.0\n60.0\n50.0\n50.0\n50.0\n40.0\n40.0\n100300\n\n\n3\n100400 Karikari Peninsula\n860.0\n1040.0\n970.0\n1280.0\n1300.0\n1300.0\n1360.0\n1400.0\n1410.0\n100400\n\n\n4\n100500 Tangonge\n940.0\n1010.0\n1090.0\n1240.0\n1180.0\n1180.0\n1230.0\n1240.0\n1260.0\n100500\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2256\n400013 Snares Islands\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n400013\n\n\n2257\n400014 Oceanic Antipodes Islands\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n400014\n\n\n2258\n400015 Antipodes Islands\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n400015\n\n\n2259\n400016 Ross Dependency\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n400016\n\n\n2260\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n2261 rows √ó 11 columns\n\n\n\nWait! What?\n\nlet‚Äôs have a look what we did here\nwe created a new column SA22023_V1 in the population dataset\nwe used the Area column as an input\n\nfor example 100100 North Cape\nbut we didn‚Äôt copy the whole content from Area into SA2, we only took some of it\nNOW: This is a very important step and applies to so many other datasets and research questions! Please pay special attention! Always think of the outliers!\n\nwe could have simply assumed that each of these IDs is 6 digits long\nbut that might not be the case\nin a different context: University of Auckland has an ID of often (!) 3 characters followed by 3 numbers\n\noften! is the key to the key (pun intended) here\nif some of these names, for example, are taken frequently, 3 characters might not be enough\netc\n\n\nso, what do we do to minimise the risk of errors?\n\nwe use something called Regex or Regular Expression\nkeeping the scope of this session in mind, think of it as a defined set of rules that we can apply to a string to find/match things\n\n\nr'(\\d+)': This is a raw string containing a regular expression.\n\\d: Matches any digit (0-9).\n+: Matches one or more of the preceding element (in this case, one or more digits).\n(): Capturing group, indicating that we want to extract the digits.\n\nby using this, we can extract digits (any number of them greater 0) from a string\nand we put them together in one capture group\n\n\nLet‚Äôs compare the file types in the columns - Area that came with the dataset - and SA2 that we just created - we will use the first row for the sake of simplicity; important side-note: Python is zero-indexed, more in the Python session on Wednesday\n\n# Selecting the first row\nfirst_row = population.iloc[0]\n\n# Inspecting datatypes of the first row elements\nfirst_row_dtypes = first_row.apply(type)\nprint(first_row_dtypes)\n\nArea              &lt;class 'str'&gt;\n1996    &lt;class 'numpy.float64'&gt;\n2001    &lt;class 'numpy.float64'&gt;\n2006    &lt;class 'numpy.float64'&gt;\n2013    &lt;class 'numpy.float64'&gt;\n2018    &lt;class 'numpy.float64'&gt;\n2019    &lt;class 'numpy.float64'&gt;\n2020    &lt;class 'numpy.float64'&gt;\n2021    &lt;class 'numpy.float64'&gt;\n2022    &lt;class 'numpy.float64'&gt;\nSA2               &lt;class 'str'&gt;\nName: 0, dtype: object\n\n\nthis means that both are ‚Äòstrings‚Äô that contain a number; this is often another common challenge!\nNow let‚Äôs merge the two datasets; but wait, before we do that, let‚Äôs have a look at the column names and what this implies\nZOOM Poll: Do you see any challange if we had these\n\nSA22023_V1 ,SA22023_1 ,SA220232 ,LAND_AREA_ ,AREA_SQ_KM ,Shape_Leng ,geometry ,Area ,1996 ,2001 ,2006 ,2013 ,2018 ,2019 ,2020 ,2021 ,2022 ,SA2\n\nwe would just have some numbers as column names while this might be totally acceptable for us, now, what if we look at the data 5 years from now, or someone else does? there are two ways to address this: - we can rename the columns - we can accompany our dataset and code with a readme file (you might have participates in the session Keeping Your Spreadsheets Tidy) - which one to pick depends - for Mechanical engineering, it might be unnecessarily hard to keep all the units (that might in turn have special characters or fractions, etc.) in the column names, here a readme.txt file is far superior - for our given use-case, we will rename the columns by adding some additional text (to the front, i.e.¬†a prefix) - let‚Äôs find the relevant column numbers (remember: Python is zero-indexed!)\n\n# Display the index number of each column\nfor index, column in enumerate(population.columns):\n    print(f'Index: {index}, Column: {column}')\n\nIndex: 0, Column: Area\nIndex: 1, Column: 1996\nIndex: 2, Column: 2001\nIndex: 3, Column: 2006\nIndex: 4, Column: 2013\nIndex: 5, Column: 2018\nIndex: 6, Column: 2019\nIndex: 7, Column: 2020\nIndex: 8, Column: 2021\nIndex: 9, Column: 2022\nIndex: 10, Column: SA2\n\n\n\n# Add a prefix to the right dataframe's columns (excluding the merge key)\nprefix = 'population_in_year_'\npopulation= population.rename(columns={col: prefix + col for col in population.columns[1:10]})\npopulation\n\n\n\n\n\n\n\n\nArea\npopulation_in_year_1996\npopulation_in_year_2001\npopulation_in_year_2006\npopulation_in_year_2013\npopulation_in_year_2018\npopulation_in_year_2019\npopulation_in_year_2020\npopulation_in_year_2021\npopulation_in_year_2022\nSA2\n\n\n\n\n0\n100100 North Cape\n1710.0\n1520.0\n1380.0\n1470.0\n1660.0\n1690.0\n1750.0\n1800.0\n1820.0\n100100\n\n\n1\n100200 Rangaunu Harbour\n2050.0\n2100.0\n2070.0\n2200.0\n2410.0\n2470.0\n2580.0\n2620.0\n2640.0\n100200\n\n\n2\n100300 Inlets Far North district\n190.0\n140.0\n70.0\n60.0\n50.0\n50.0\n50.0\n40.0\n40.0\n100300\n\n\n3\n100400 Karikari Peninsula\n860.0\n1040.0\n970.0\n1280.0\n1300.0\n1300.0\n1360.0\n1400.0\n1410.0\n100400\n\n\n4\n100500 Tangonge\n940.0\n1010.0\n1090.0\n1240.0\n1180.0\n1180.0\n1230.0\n1240.0\n1260.0\n100500\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2256\n400013 Snares Islands\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n400013\n\n\n2257\n400014 Oceanic Antipodes Islands\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n400014\n\n\n2258\n400015 Antipodes Islands\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n400015\n\n\n2259\n400016 Ross Dependency\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n400016\n\n\n2260\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n2261 rows √ó 11 columns"
  },
  {
    "objectID": "Plots.html",
    "href": "Plots.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "Code\nimport plotly.express as px\nimport pandas as pd\npd.options.plotting.backend = \"plotly\"\nimport plotly.io as pio\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.cm as cm\nimport plotly.subplots as sp\n\n\n\n\nCode\n# Custom colors\ncustom_colors = ['#00467F', '#009AC7', '#8D9091', '#A71930', '#7D0063', '#D2492A', '#55A51C',\n                 '#4F2D7F', '#005B82', '#00877C', '#0039A6', '#BA4482', '#006990']\n\n\n\n\nCode\npio.renderers.default = \"notebook\"\n# Read data from the CSV file\ndf = pd.read_csv('./InputDataR1.csv')\ndf_raw = df\ndfR2 = pd.read_csv('./InputDataR2.csv')\ndf2_raw = dfR2\ndf2 = df.drop([0, 1])\ndfR22 = dfR2.drop([0, 1])\n\n\n\noption_counts = df2['Q1'].value_counts()\noption_countsR2 = dfR22['Q1'].value_counts()\n\n# Create a DataFrame from the value_counts() result\noption_counts_df = pd.DataFrame({'Option': option_counts.index, 'R1': option_counts.values})\noption_counts_dfR2 = pd.DataFrame({'Option': option_countsR2.index, 'R2': option_countsR2.values})\noption_counts_df = option_counts_df.merge(option_counts_dfR2, on=\"Option\", how=\"outer\")\n\n# print(option_counts_df)\ntotal_r1 = option_counts_df.R1.sum()\ntotal_r2 = option_counts_df.R2.sum()\nattendance_ratio = total_r1/total_r2\n\ntrace1 = go.Pie(\n     values=option_counts_df.R1, \n     labels=option_counts_df.Option,\n     domain=dict(x=[0, 0.5*attendance_ratio]),\n     name=\"Run #1\",\n     hole=0.4,\n     hoverinfo=\"label+percent+name\",\n     title=f\"Run#1 &lt;br&gt; [{int(total_r1)}]\",\n     marker_colors=custom_colors\n)\n\n\n\ntrace2 = go.Pie(\n     values=option_counts_df.R2, \n     labels=option_counts_df.Option,\n     domain=dict(x=[0.5, 1.0]),\n     name=\"Run #2\",\n     hole=0.4,\n     hoverinfo=\"label+percent+name\",\n     title=f\"Run#2 &lt;br&gt; [{int(total_r2)}]\",\n     marker_colors=custom_colors\n)\n\nlayout = go.Layout(\n        font=dict(\n            family=\"Verdana\",\n            size=18,\n        ),\n#      legend=dict(\n#         x=0.5,  # Center the legend horizontally\n#         y=-0.1,  # Position the legend just below the plot\n#         xanchor='center',  # Set the x anchor to center\n#         yanchor='top',  # Set the y anchor to the top\n#     )\n)\n#     title=\"Participants' Background\")\n\ndata = [trace1, trace2]\nfig = go.Figure(data=data, layout=layout)\nfig.show()\n# Save the figure as an SVG file\npio.write_image(fig, './UpskillingResearchersInML_Assets/ParticipantsBackground.svg', width=1800, height=600, scale=1)  # Adjust the scale as needed)\n\n\n                                                \n\n\n\n\nCode\n# print(option_counts_df.R1/option_counts_df.R1.sum()*100)\n# assign this as a new column to the existing dataframe option_counts_df\noption_counts_df['percentR1'] = (option_counts_df['R1'] / option_counts_df['R1'].sum() * 100).fillna(0)\noption_counts_df['percentR2'] = (option_counts_df['R2'] / option_counts_df['R2'].sum() * 100).fillna(0)\n\nprint(option_counts_df)\n\n\n                               Option   R1   R2  percentR1  percentR2\n0    Biomedical and clinical sciences  6.0  3.0      37.50  16.666667\n1                         Engineering  4.0  8.0      25.00  44.444444\n2        Built environment and design  1.0  NaN       6.25   0.000000\n3                           Economics  1.0  NaN       6.25   0.000000\n4                   Chemical sciences  1.0  NaN       6.25   0.000000\n5               Mathematical sciences  1.0  1.0       6.25   5.555556\n6                 Biological sciences  1.0  1.0       6.25   5.555556\n7                           Education  1.0  NaN       6.25   0.000000\n8                     Health sciences  NaN  4.0       0.00  22.222222\n9  Information and computing sciences  NaN  1.0       0.00   5.555556\n\n\n\n\nCode\noption_countsOSR1 = df2['Q2'].value_counts()\noption_countsOSR2 = dfR22['Q2'].value_counts()\n# Create a DataFrame from the value_counts() result\n\noption_counts_df = pd.DataFrame({'Option': option_countsOSR1.index, 'R1': option_countsOSR1.values})\noption_counts_dfR2 = pd.DataFrame({'Option': option_countsOSR2.index, 'R2': option_countsOSR2.values})\noption_counts_df = option_counts_df.merge(option_counts_dfR2, on=\"Option\", how=\"outer\")\n\n\ntrace1 = go.Pie(\n     values=option_counts_df.R1, \n     labels=option_counts_df.Option,\n     domain=dict(x=[0.0, 0.45]),  # Adjust the x values\n     name=\"Run #1\",\n     hole=0.4,\n     hoverinfo=\"label+percent+name\",\n     title=f\"Run#1 &lt;br&gt; [{int(total_r1)}]\",\n     marker_colors=custom_colors\n)\n\n\n\ntrace2 = go.Pie(\n     values=option_counts_df.R2, \n     labels=option_counts_df.Option,\n     domain=dict(x=[0.55, 1.0]),  # Adjust the x values\n     name=\"Run #2\",\n     hole=0.4,\n     hoverinfo=\"label+percent+name\",\n     title=f\"Run#2 &lt;br&gt; [{int(total_r2)}]\",\n     marker_colors=custom_colors\n)\n\nlayout = go.Layout(\n#     boxgap=0.1,\n    font=dict(\n            family=\"Verdana\",\n            size=18,\n        ),\n\n)\n#     title=\"Participants' Background\")\ndata = [trace1, trace2]\nfig = go.Figure(data=data, layout=layout)\nconfig = {'responsive': False}\nfig.show()\n\n# Save the figure as an SVG file\npio.write_image(fig, './UpskillingResearchersInML_Assets/ParticipantsOS.svg', width=1800, height=600, scale=1)  # Adjust the scale as needed)\n\n\n                                                \n\n\n\n\nCode\n# List of column names you want to plot\ncolumns_to_plot = ['Q3_1', 'Q3_2', 'Q3_3', 'Q3_4', 'Q3_5', 'Q3_6']\n\ndef plot_columns_from_dataframe(dataframe1, dataframe2, columns_to_plot):\n    # String to be stripped from each element\n    string_to_strip = \"Please rate your level of agreement with the following statements (0 = complete disagreement, 100 = complete agreement). - \"\n\n    for column in columns_to_plot:\n        # Check if the column contains string values before applying .str.replace()\n        if df_raw[column].dtype == 'object':\n            df_raw[column] = df_raw[column].str.replace(string_to_strip, '', case=False)\n\n    # Convert the columns to float, handling non-numeric values by replacing them with NaN\n    for column in columns_to_plot:\n        dataframe1[column] = pd.to_numeric(dataframe1[column], errors='coerce')\n\n    # Create subplots\n    fig = make_subplots(rows=1, cols=1, shared_yaxes=True)\n\n    # custom_colors = ['color1', 'color2', 'color3', 'color4', 'color5', 'color6']  # Define your custom colors\n\n    for it_number, column in enumerate(columns_to_plot):\n        median_value_df1 = dataframe1[column].median()\n        subplot_df1 = go.Box(\n            y=dataframe1[column],\n            boxpoints='all',\n            jitter=0.3,\n            pointpos=-1.8,\n            line=dict(color=custom_colors[it_number]),\n            marker=dict(color=custom_colors[it_number]),\n            name=df_raw.loc[0,column]\n        )\n\n        median_value_df2 = dataframe2[column].median()\n        subplot_df2 = go.Box(\n            y=dataframe2[column],\n            boxpoints='all',\n            jitter=0.3,\n            pointpos=-1.8,\n            line=dict(color=custom_colors[it_number]),\n            marker=dict(color=custom_colors[it_number]),\n            showlegend=False,\n            # in f notation prepend Run#2 to the name followed b the it_number variable\n            name=f\"Run#2 Q {it_number+1}\"\n        )\n\n        # Add subplots to the figure\n        fig.add_trace(subplot_df1, row=1, col=1)\n        fig.add_trace(subplot_df2, row=1, col=1)\n\n        # # Add median annotations\n        # fig.add_annotation(\n        #     x=it_number + 1,\n        #     y=median_value_df1,\n        #     text=f'Median: {median_value_df1:.2f}',\n        #     font=dict(size=14, color=\"black\"),\n        #     showarrow=True,\n        #     arrowhead=7,\n        #     ax=0,\n        #     ay=-20,\n        #     row=1,\n        #     col=1\n        # )\n\n        # fig.add_annotation(\n        #     x=it_number + 1,\n        #     y=median_value_df2,\n        #     text=f'Median: {median_value_df2:.2f}',\n        #     font=dict(size=14, color=\"black\"),\n        #     showarrow=True,\n        #     arrowhead=7,\n        #     ax=0,\n        #     ay=-20,\n        #     row=1,\n        #     col=2\n        # )\n\n    # Customize the layout\n    fig.update_layout(\n        title=\"Agreement with statements: 0 = complete disagreement, 100 = complete agreement, Run#1 left, Run#2 right\",\n        font=dict(\n            family=\"Verdana\",\n            size=18,\n        ),\n        # xaxis=dict(title=\"Columns\"),\n        # yaxis=dict(title=\"Values\")\n    )\n\n    # do not show the x axis labels\n    fig.update_xaxes(showticklabels=False)\n\n    # Add a subtitle-like text as an annotation\n    fig.add_annotation(\n        text=\"median across all data for Run#1: 85.5, Run #2: 86.25\",\n        xref=\"paper\", yref=\"paper\",  # Position relative to the chart\n        x=0.5, y=1.05,  # Adjust the position\n        showarrow=False,  # Hide arrow\n        font=dict(size=16)  # Customize font size\n    )\n\n    # # Add a horizontal line to the boxplots\n    # average_values_df1 = dataframe1[columns_to_plot].mean()\n    # overall_avg_df1 = average_values_df1.mean()\n\n    # average_values_df2 = dataframe2[columns_to_plot].mean()\n    # overall_avg_df2 = average_values_df2.mean()\n\n    # fig.add_shape(\n    #     go.layout.Shape(\n    #         type=\"line\",\n    #         x0=0,\n    #         x1=len(columns_to_plot) + 1,\n    #         y0=overall_avg_df1,\n    #         y1=overall_avg_df1,\n    #         line=dict(color=\"red\", width=2),\n    #     ),\n    #     row=1,\n    #     col=1\n    # )\n\n    # fig.add_shape(\n    #     go.layout.Shape(\n    #         type=\"line\",\n    #         x0=0,\n    #         x1=len(columns_to_plot) + 1,\n    #         y0=overall_avg_df2,\n    #         y1=overall_avg_df2,\n    #         line=dict(color=\"red\", width=2),\n    #     ),\n    #     row=1,\n    #     col=2\n    # )\n\n    # fig.add_annotation(\n    #     x=len(columns_to_plot) + 1,\n    #     y=overall_avg_df1,\n    #     text=f'Overall avg: {overall_avg_df1:.2f}',\n    #     font=dict(size=14, color=\"red\"),\n    #     ax=0,\n    #     ay=20,\n    #     row=1,\n    #     col=1\n    # )\n\n    # fig.add_annotation(\n    #     x=len(columns_to_plot) + 1,\n    #     y=overall_avg_df2,\n    #     text=f'Overall avg: {overall_avg_df2:.2f}',\n    #     font=dict(size=14, color=\"red\"),\n    #     ax=0,\n    #     ay=20,\n    #     row=1,\n    #     col=2\n    # )\n\n    # Show the figure\n    fig.show()\n    # Save the figure as an SVG file\n    pio.write_image(fig, './UpskillingResearchersInML_Assets/ParticipantsAgreement.svg', width=1800, height=600, scale=1)  # Adjust the scale as needed)\n\n# Example usage:\n# Create or load your DataFrames and specify the list of columns to plot\n# df1 = pd.read_csv('your_dataframe1.csv')  # Or create your DataFrame\n# dataframe2 = pd.read_csv('your_dataframe2.csv')  # Or create your DataFrame\n# columns_to_plot = ['Q3_1', 'Q3_2', 'Q3_3', 'Q3_4', 'Q3_5', 'Q3_6']\n# plot_columns_from_dataframe(df1, dataframe2, columns_to_plot)\ncolumns_to_plot = ['Q3_1', 'Q3_2', 'Q3_3', 'Q3_4', 'Q3_5', 'Q3_6']\nplot_columns_from_dataframe(df2, dfR22, columns_to_plot)\n\n\n\n                                                \n\n\n\n\nCode\n# Calculate the median for each column\nmedians = df2[columns_to_plot].median()\n\n# Calculate the metric as the median of medians\noverall_median = medians.median()\n\nprint(overall_median)\n\n# Calculate the median for each column\nmedians = dfR22[columns_to_plot].median()\n\n# Calculate the metric as the median of medians\noverall_median = medians.median()\n\nprint(overall_median)\n\n\n\n85.5\n86.25\n\n\n\n\nCode\n# Load data from CSV into the 'zoom' DataFrame\nzoom = pd.read_csv(\"ZoomStats.csv\")\n\n# Create a list of unique days\nunique_days = zoom['Day'].unique()\n\n\n\n# Create subplots for each day\nfig = go.Figure()\n# config = {'responsive': False}\n\n\n# Create a bar for Run1 and Run2 for each unique day\nx_labels = []\nfor day in unique_days:\n    day_data = zoom[zoom['Day'] == day]\n    \n    fig.add_trace(go.Bar(\n        x=[f'Day {day} - Run1', f'Day {day} - Run2'],\n        y=[day_data['Run1'].values[0], day_data['Run2'].values[0]],\n        name=f'Day {day}',\n        text=[day_data['Run1'].values[0], day_data['Run2'].values[0]],\n        textposition='outside',  # Place the value annotations outside the bars\n        showlegend=False,  # Hide the legend\n        marker_color=[custom_colors[0], custom_colors[1]]\n    ))\n    \n    x_labels.extend([f'Day {day} - Run1', f'Day {day} - Run2'])\n\n# Update layout for the overall figure\nfig.update_layout(\n    title='Number of participants in Zoom meetings per day',\n    xaxis=dict(\n        # title='Day and Run',\n        tickmode='array',\n        tickvals=list(range(len(x_labels))),\n        ticktext=x_labels\n    ),\n    # yaxis=dict(title='Value'),\n    barmode='group',\n    # bargap=0.1,  # Adjust the bargap to your preferred spacing\n    font=dict(\n            family=\"Verdana\",\n            size=18,\n        ),\n)\n\n\n\nhighest_value = max(zoom[['Run1', 'Run2']].values.flatten())\n# print(highest_value)\n\n\nfig.update_yaxes(range=[0, highest_value+4])  # Set the initial y-axis range\n\n# Add a subtitle-like text as an annotation\nfig.add_annotation(\n    text=\"deduplicated, not including instructors or helpers\",\n    xref=\"paper\", yref=\"paper\",  # Position relative to the chart\n    x=0.5, y=1.05,  # Adjust the position\n    showarrow=False,  # Hide arrow\n    font=dict(size=16)  # Customize font size\n)\n\n\n# Show the figure\nfig.show()\n\n# Save the figure as an SVG file\npio.write_image(fig, './UpskillingResearchersInML_Assets/ZoomParticipants.svg')\n\n\n                                                \n\n\n\n\nCode\ndf_promR1 = df2['Q4']\ndf_promR1\ndf_promR1.dropna(inplace=True)\ndf_promR1.astype(int)\ndf_promR2 = dfR22['Q4']\ndf_promR2\ndf_promR2.dropna(inplace=True)\ndf_promR2.astype(int)\n\npromote = pd.concat([df_promR1.astype(int), df_promR2.astype(int)], axis=1)\n\n# # Rename the columns if needed (optional)\npromote.columns = ['Q4_R1', 'Q4_R2']\npromote\n\n# flatten the dataframe 'promote' \n# promote = promote.stack().reset_index()\n\noption_counts_R1 = promote['Q4_R1'].value_counts()\noption_counts_R2 = promote['Q4_R2'].value_counts()\n\npromote2 = pd.concat([option_counts_R1.astype(int), option_counts_R2.astype(int)], axis=1)\npromote2.columns = ['Q4_R1', 'Q4_R2']\npromote2\n\n# data_type = type(promote2['Q4_R1'].iloc[0])\n# print(data_type)\n\n# promote2.plot(kind='bar')\n\n# Create subplots for each day\nfig = go.Figure()\n# config = {'responsive': False}\n\n\n# Create a bar for Run1 and Run2 for each unique day\n\nfig.add_trace(go.Bar(\n    x=promote2.index,\n    y=promote2['Q4_R1'],\n    name=\"Run #1\",\n    text=promote2['Q4_R1'].values,\n    textposition='outside',  # Place the value annotations outside the bars\n    # showlegend=False,  # Hide the legend\n    marker_color=custom_colors[0]\n)\n)\n\nfig.add_trace(go.Bar(\n    x=promote2.index,\n    y=promote2['Q4_R2'],\n    name=\"Run #2\",\n    text=promote2['Q4_R2'].values,\n    textposition='outside',  # Place the value annotations outside the bars\n    # showlegend=False,  # Hide the legend\n    marker_color=custom_colors[1]\n)\n)\n\n\n# Update layout for the overall figure\nfig.update_layout(\n    title='How likely would you be to recommend this workshop to a colleague?',\n\n    barmode='group',\n    bargap=0.1,  # Adjust the bargap to your preferred spacing\n    font=dict(\n            family=\"Verdana\",\n            size=18,\n        ),\n)\n\n\n\n# Add a subtitle-like text as an annotation\nfig.add_annotation(\n    text=\"0 = not likely at all ... 10 = extremely likely\",\n    xref=\"paper\", yref=\"paper\",  # Position relative to the chart\n    x=0.5, y=-0.15,  # Adjust the position\n    showarrow=False,  # Hide arrow\n    font=dict(size=16)  # Customize font size\n)\n\n# Add a subtitle-like text as an annotation\nfig.add_annotation(\n    text=\"deduplicated, not including instructors or helpers\",\n    xref=\"paper\", yref=\"paper\",  # Position relative to the chart\n    x=0.5, y=1.05,  # Adjust the position\n    showarrow=False,  # Hide arrow\n    font=dict(size=16)  # Customize font size\n)\n\nfig.update_xaxes(range=[0, 11])  # Set the initial x-axis range\nfig.update_yaxes(range=[0, 10])  # Set the initial y-axis range\n\n# Update x-axis ticks to display integers from 0 to 10\nfig.update_xaxes(\n    tickmode='array',\n    tickvals=list(range(11)),  # Set tick values from 0 to 10\n    ticktext=list(map(str, range(11)))  # Set tick labels as strings of integers from 0 to 10\n)\n\n# # Show the figure\nfig.show()\npio.write_image(fig, './UpskillingResearchersInML_Assets/ParticipantsRecommend.svg', width=1800, height=600, scale=1)  # Adjust the scale as needed)\n\n\n\n\n\n                                                \n\n\n\n\nCode\n# Load data from CSV into the 'zoom' DataFrame\nzoom = pd.read_csv(\"ZoomStats.csv\")\nzoom\n\n\n# Assuming you have a DataFrame or data source named 'zoom'\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=zoom['Day'], y=zoom['Run1'], mode='lines+markers', name='Run#1', line=dict(width=2, color=custom_colors[0]), marker=dict(size=8, color=custom_colors[0])))\nfig.add_trace(go.Scatter(x=zoom['Day'], y=zoom['Run2'], mode='lines+markers', name='Run#2', line=dict(width=2, color=custom_colors[1]), marker=dict(size=8, color=custom_colors[1])))\n\n\ndef format_data_label(value):\n    if np.isnan(value) or value == \"\":\n        return \"\"\n    else:\n        return f\"{value:.0f}\"\n\nfig.update_layout(title='Attendees per Zoom session',\n                  xaxis_title='Day',\n                #   yaxis_title='Value'\n                  )\n\n# Create a text column for data values with custom formatting\ntext_values_run1 = [format_data_label(val) for val in zoom['Run1']]\ntext_values_run2 = [format_data_label(val) for val in zoom['Run2']]\n\n# Add data labels to each trace using add_trace\nfig.add_trace(go.Scatter(x=zoom['Day'], y=zoom['Run1'], mode='text', text=text_values_run1, textposition='top center', showlegend=False))\nfig.add_trace(go.Scatter(x=zoom['Day'], y=zoom['Run2'], mode='text', text=text_values_run2, textposition='bottom center', showlegend=False))\n\n# Set the y-axis scale to [0, 37]\nfig.update_yaxes(range=[0.1, 5.1])\nfig.update_yaxes(range=[0, 37])\n\n# Set x-axis ticks to integers\nfig.update_xaxes(tickmode='linear', dtick=1)\n\n\n\n\nfig.update_layout(\n        font=dict(\n            family=\"Verdana\",\n            size=18,\n        ),)\n\n# Add a subtitle-like text as an annotation\nfig.add_annotation(\n    text=\"deduplicated, not including instructors or helpers\",\n    xref=\"paper\", yref=\"paper\",  # Position relative to the chart\n    x=0.5, y=1.05,  # Adjust the position\n    showarrow=False,  # Hide arrow\n    font=dict(size=16)  # Customize font size\n)\n\n# Set hoverformat to display data labels without decimal places\nfig.update_traces(hoverinfo=\"y+text\", hoverlabel=dict(namelength=0), hovertemplate=\"%{y:.0f}\")\n\n\nfig.show()\n\n# Save the figure as an SVG file\npio.write_image(fig, './UpskillingResearchersInML_Assets/ZoomParticipantsLine.svg')"
  }
]